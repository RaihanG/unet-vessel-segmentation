"""
File name: evaluate_segmentation_functions.py
Author: Jana Rieger
Date created: 07/25/2018

This file contains helper functions for evaluate_segmentation.py script.
"""

import os
import xml.etree.cElementTree as ET
import csv
import numpy as np
import subprocess

# compare segmentations based on the EvaluateSegmentation software of Taha
from Unet import config


def segment_comparison(goldstandard_path, segmentation_path, executable_path, eval_result_path, threshold, measures):
    """
    Helper function. Runs the EvaluateSegmentation executable to calculate different performance measures and save as xml file.

    :param gt_path: path to ground-truth label.
    :param segmentation_path: path to predicted segmentation.
    :param executable_path: path to EvaluateSegmentation.exe.
    :param eval_result_path: path to save the result.
    :param threshold: threshold value between 0.0 and 1.0
    :param measures: string of measures
    """
    print(measures)
    command_string = executable_path + " " + goldstandard_path + " " + segmentation_path + " -use " + measures + " -xml " + eval_result_path + " -thd " + str(threshold)
    print(command_string)
    os.system(command_string)


def parse_xml_to_csv(xml_path, csv_path, run_params=None):
    """
    Helper function. Parses the xml file to csv.

    :param xml_path: path to xml file.
    :param csv_path: path to csv file.
    :param run_params: hyperparameters used for training the U-net model.
    """
    # get all the metrics as a list
    if run_params is None:
        run_params = {}
    list_of_measures = []
    measures_values = []
    tree = ET.parse(xml_path)
    root = tree.getroot()
    for child in root.findall(".//metrics/*"):
        list_of_measures.append(child.attrib["symbol"])
        value = child.attrib["value"]
        measures_values.append(value)

    with open(csv_path, 'a+') as f1:
        writer = csv.writer(f1)
        if os.path.isfile(csv_path) and os.path.getsize(csv_path) == 0:
            writer.writerow(list(run_params.keys()) + list_of_measures)
        writer.writerow(list(run_params.values()) + measures_values)


# calculate_sensibility
def calculate_sensibility(metrics_dic):
    try:
        fp = int(metrics_dic["FP"])
        fn = int(metrics_dic["FN"])
        tp = int(metrics_dic["TP"])
        valsensibility = (1 - fp / (tp + fn)) * 100
    except (KeyError, ZeroDivisionError):
        valsensibility = np.nan

    return round(valsensibility, 6)


# calculate_conformity
def calculate_conformity(metrics_dic):
    try:
        fp = int(metrics_dic["FP"])
        fn = int(metrics_dic["FN"])
        tp = int(metrics_dic["TP"])
        valconformity = (1 - (fp + fn) / tp) * 100
    except (KeyError, ZeroDivisionError):
        valconformity = np.nan

    return round(valconformity, 6)


# create dictionary of
def create_dict_from_xml(xml_path, metrics_list=None):
    if metrics_list is None:
        metrics_list = ["TP", "FP", "TN", "FN"]

    value_metrics_dic = []
    tree = ET.parse(xml_path)
    root = tree.getroot()
    for child in root.findall(".//metrics/*"):
        if child.tag in metrics_list:
            value_metrics_dic.append(child.attrib["value"])
    metrics_dic = dict(zip(metrics_list, value_metrics_dic))
    return metrics_dic


def sensibility_conformity_to_xml(xml_path):
    """
    Insert Sensibility and Conformity values into Evaluation xml.

    :param xml_path: path to xml file generated by EvaluateSegmentation.exe
    """
    print('ADDING SENSBIL and CFM to:', xml_path)
    tree = ET.parse(xml_path)
    root = tree.getroot()

    metrics_dic = create_dict_from_xml(xml_path)

    valsensibility = calculate_sensibility(metrics_dic)
    valconformity = calculate_conformity(metrics_dic)

    sensibility_attributes = {"name": "sensibility", "value": str(valsensibility), "symbol": "SENSBIL",
                              "type": "similarity", "unit": "voxel"}
    SENSBIL = ET.Element("SENSBIL", attrib=sensibility_attributes)
    conformity_attributes = {"name": "conformity", "value": str(valconformity), "symbol": "CFM", "type": "similarity",
                             "unit": "voxel"}
    CFM = ET.Element("CFM", attrib=conformity_attributes)

    root[2].insert(2, SENSBIL)
    root[2].insert(3, CFM)
    tree.write(xml_path)


# noinspection PyTypeChecker
def parse_xml_to_csv_avg_for_patients(xml_paths, csv_path, run_params):
    """
    Helper function. Parses the xml file to csv and averages the measures over all patient in particular set.

    :param xml_path: path to xml file.
    :param csv_path: path to csv file.
    :param run_params: hyperparameters used for training the U-net model.
    """
    # get all the measures as a list
    measures_values_all_patients = []
    measures_symbols = []
    for i, path in enumerate(xml_paths):
        measures_values = []
        tree = ET.parse(path)
        root = tree.getroot()
        for child in root.findall(".//metrics/*"):
            if i == 0:
                measures_symbols.append(child.attrib["symbol"])
            measures_values.append(child.attrib["value"])
        measures_values_all_patients.append(measures_values)

    # count average for each metric
    measures_values_avg = np.mean(np.asarray(measures_values_all_patients, dtype=np.float32), axis=0)
    print(measures_values_avg)

    with open(csv_path, 'a+') as f1:
        writer = csv.writer(f1)
        if os.path.isfile(csv_path) and os.path.getsize(csv_path) == 0:
            writer.writerow(list(run_params.keys()) + measures_symbols)
        writer.writerow(list(run_params.values()) + measures_values_avg.tolist())


def evaluate_segmentation(patch_size, num_epochs, batch_size, lr, dropout, num_patients_train, num_patients_val,
                          patients_segmentation, threshold, data_dirs, dataset, executable_path, csv_path_per_patient,
                          csv_path, measures):
    """
        Main function for evaluating segmentation.

        :param patch_size: training patch size.
        :param num_epochs: number of epochs in training.
        :param batch_size: training batch size.
        :param lr: training learning rate.
        :param dropout: training dropout rate.
        :param num_patients_train: number of patients in training set.
        :param num_patients_val: number of patients in validation set.
        :param patients_segmentation: number of patients in the particular set on which the segmentation performance is
        evaluated.
        :param threshold: threshold value.
        :param data_dirs: directory where the segmentations are saved.
        :param dataset: train/val/test.
        :param executable_path:  path to EvaluateSegmentation.exe.
        :param csv_path_per_patient: path to csv file with results per patient.
        :param csv_path: path to csv file with results averaged over all patients.
        :param measures: string of measures to calculate.
        """
    # create the name of current run
    run_name = config.get_run_name(patch_size, num_epochs, batch_size, lr, dropout,
                                   num_patients_train, num_patients_val)
    print(run_name)

    xml_paths = []

    for patient in patients_segmentation:
        print('________________________________________________________________________________')
        print('patient:', patient)
        print('patch size', patch_size)
        print('batch size', batch_size)
        print('learning rate', lr)
        print('dropout', dropout)
        print('threshold', threshold)

        # load labels and segmentations
        label_path = data_dirs[dataset] + patient + '_label.nii'
        segmentation_path = config.get_probs_filepath(run_name, patient, dataset)
        # for saving results of evaluate segmentation to xml and to csv
        xml_path_patient = config.get_eval_segment_dataset_xmlpath(run_name, patient, dataset)
        xml_paths.append(xml_path_patient)

        # compare the segmentation with ground truth and save the xml file in the results folder
        segment_comparison(label_path, segmentation_path, executable_path, xml_path_patient, threshold, measures)

        # parse the generated xmls and insert two more metrics: Sensibility and Conformity
        sensibility_conformity_to_xml(xml_path_patient)

        # parse the xml files in each folder, do stats and save the dataframes as csvs with the parse_xml
        # function
        run_params = {'patch size': patch_size, 'num epochs': num_epochs, 'batch size': batch_size,
                      'learning rate': lr, 'dropout': dropout, 'patient': patient}
        parse_xml_to_csv(xml_path_patient, csv_path_per_patient, run_params)

    run_params = {'patch size': patch_size, 'num epochs': num_epochs, 'batch size': batch_size,
                  'learning rate': lr, 'dropout': dropout}
    parse_xml_to_csv_avg_for_patients(xml_paths, csv_path, run_params)
